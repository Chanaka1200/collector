package main

import (
	"bytes"
	"encoding/binary"
	"io/ioutil"
	"log"
	"os"
	"os/signal"
	"time"
	"unsafe"

	"github.com/cilium/ebpf/link"
	"github.com/cilium/ebpf/rlimit"
	ourperf "github.com/unvariance/collector/pkg/perf"
	"github.com/unvariance/collector/pkg/perf_ebpf"
	"golang.org/x/sys/unix"
)

// Note: taskCounterEvent is auto-generated by bpf2go
// Note: taskCounterRmidMetadata is auto-generated by bpf2go

// nanotime returns monotonic time in nanoseconds. We get this from the runtime
//
//go:linkname nanotime runtime.nanotime
func nanotime() int64

// dumpRmidMap dumps all valid RMIDs and their metadata
func dumpRmidMap(objs *taskCounterObjects) {
	var key uint32
	var metadata taskCounterRmidMetadata

	log.Println("Dumping RMID map contents:")
	log.Println("Index\tRMID\tComm\tTgid\tTimestamp\tValid")
	log.Println("-----\t----\t----\t----\t---------\t-----")

	for i := uint32(0); i < 512; i++ { // max_entries is 512 from task_counter.c
		key = i
		err := objs.RmidMap.Lookup(&key, &metadata)
		if err != nil {
			continue // Skip if error looking up this RMID
		}

		if metadata.Valid == 1 {
			// Convert []int8 to []byte for the comm field
			commBytes := make([]byte, len(metadata.Comm))
			for i, b := range metadata.Comm {
				commBytes[i] = byte(b)
			}
			// Convert comm to string, trimming null bytes
			comm := string(bytes.TrimRight(commBytes, "\x00"))
			log.Printf("%d\t%d\t%s\t%d\t%d\t%d\n",
				i, key, comm, metadata.Tgid, metadata.Timestamp, metadata.Valid)
		}
	}
	log.Println("") // Add blank line after dump
}

func main() {
	// Allow the current process to lock memory for eBPF resources
	if err := rlimit.RemoveMemlock(); err != nil {
		log.Fatal(err)
	}

	// Load pre-compiled programs and maps into the kernel
	objs := taskCounterObjects{}
	if err := loadTaskCounterObjects(&objs, nil); err != nil {
		log.Fatal(err)
	}
	defer objs.Close()

	// Attach the tracepoint programs
	tp, err := link.Tracepoint("memory_collector", "memory_collector_sample", objs.CountEvents, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer tp.Close()

	// Attach RMID free tracepoint first, so we don't get dangling RMIDs
	rmidFreeTp, err := link.Tracepoint("memory_collector", "memory_collector_rmid_free", objs.HandleRmidFree, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer rmidFreeTp.Close()

	// Attach RMID allocation tracepoint
	rmidAllocTp, err := link.Tracepoint("memory_collector", "memory_collector_rmid_alloc", objs.HandleRmidAlloc, nil)
	if err != nil {
		log.Fatal(err)
	}
	defer rmidAllocTp.Close()

	// Attach RMID existing tracepoint
	rmidExistingTp, err := link.Tracepoint("memory_collector", "memory_collector_rmid_existing", objs.HandleRmidExisting, nil)
	if err != nil {
		log.Fatal(err)
	}

	// Create a ReaderOptions with a large Watermark
	perCPUBufferSize := 16 * os.Getpagesize()
	opts := perf_ebpf.Options{
		BufferSize:     perCPUBufferSize,
		WatermarkBytes: uint32(perCPUBufferSize / 2),
	}

	// Create our perf map reader
	rd, err := perf_ebpf.NewPerfMapReader(objs.Events, opts)
	if err != nil {
		log.Fatal(err)
	}
	defer rd.Close()

	// Create the event openers for hardware counters
	commonOpts := unix.PerfEventAttr{
		Sample:      0,
		Sample_type: 0,
		Read_format: unix.PERF_FORMAT_TOTAL_TIME_ENABLED | unix.PERF_FORMAT_TOTAL_TIME_RUNNING,
		Bits:        0,
		Wakeup:      0,
		Bp_type:     0,
		Ext1:        0,
		Ext2:        0,
	}

	// Open cycles counter
	cyclesAttr := commonOpts
	cyclesAttr.Type = unix.PERF_TYPE_HARDWARE
	cyclesAttr.Config = unix.PERF_COUNT_HW_CPU_CYCLES
	cyclesOpener, err := NewEventOpener(objs.Cycles, cyclesAttr)
	if err != nil {
		log.Fatal(err)
	}
	defer cyclesOpener.Close()

	// Open instructions counter
	instrAttr := commonOpts
	instrAttr.Type = unix.PERF_TYPE_HARDWARE
	instrAttr.Config = unix.PERF_COUNT_HW_INSTRUCTIONS
	instrOpener, err := NewEventOpener(objs.Instructions, instrAttr)
	if err != nil {
		log.Fatal(err)
	}
	defer instrOpener.Close()

	// Open LLC misses counter
	llcAttr := commonOpts
	llcAttr.Type = unix.PERF_TYPE_HARDWARE
	llcAttr.Config = unix.PERF_COUNT_HW_CACHE_MISSES
	llcOpener, err := NewEventOpener(objs.LlcMisses, llcAttr)
	if err != nil {
		log.Fatal(err)
	}
	defer llcOpener.Close()

	// Trigger RMID dump via procfs
	if err := ioutil.WriteFile("/proc/unvariance_collector", []byte("dump"), 0644); err != nil {
		log.Fatal(err)
	}
	log.Println("Triggered RMID dump via procfs")

	// Close the RMID existing tracepoint since we're done with the dump
	if err := rmidExistingTp.Close(); err != nil {
		log.Printf("Warning: Failed to close RMID existing tracepoint: %v", err)
	}
	log.Println("Closed RMID existing tracepoint")

	// Dump RMID map after initial dump
	dumpRmidMap(&objs)

	// Catch CTRL+C
	stopper := make(chan os.Signal, 1)
	signal.Notify(stopper, os.Interrupt)

	timeout := time.After(5 * time.Second)
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	// Counter to maintain in userspace
	var totalEvents uint64 = 0

	// Start the reader
	reader := rd.Reader()

	log.Println("Waiting for events...")

	for {
		select {
		case <-stopper:
			log.Printf("Received interrupt, exiting... Total events: %d\n", totalEvents)
			dumpRmidMap(&objs) // Dump RMID map before exiting
			return
		case <-timeout:
			log.Println("Finished counting after 5 seconds")
			dumpRmidMap(&objs) // Dump RMID map before exiting
			return
		case <-ticker.C:
			// Get current monotonic timestamp before starting the batch
			startTimestamp := uint64(nanotime())
			log.Printf("Starting batch at timestamp: %d", startTimestamp)

			if err := reader.Start(); err != nil {
				log.Fatal(err)
			}

			// Process all available events that occurred before startTimestamp
			for !reader.Empty() {
				// Check if next event's timestamp is after our start timestamp
				ts, err := reader.PeekTimestamp()
				if err != nil {
					log.Printf("Error peeking timestamp: %s", err)
					break
				}

				// Skip processing this batch if we see an event from the future
				if ts > startTimestamp {
					break
				}

				ring, cpuID, err := reader.CurrentRing()
				if err != nil {
					log.Printf("Error getting current ring: %s", err)
					break
				}

				// Check for lost samples
				if ring.PeekType() == ourperf.PERF_RECORD_LOST {
					var lostCount uint64
					if err := ring.PeekCopy((*[8]byte)(unsafe.Pointer(&lostCount))[:], 8); err != nil {
						log.Printf("Error reading lost count: %s", err)
					} else {
						log.Printf("Lost %d samples on CPU %d", lostCount, cpuID)
					}
					reader.Pop()
					continue
				}

				// Parse the raw event
				size, err := ring.PeekSize()
				if err != nil {
					log.Printf("Error getting event size: %s", err)
					break
				}

				eventData := make([]byte, size-4)
				if err := ring.PeekCopy(eventData, 4); err != nil {
					log.Printf("Error copying event data: %s", err)
					break
				}

				var event taskCounterEvent
				if err := binary.Read(bytes.NewReader(eventData), binary.LittleEndian, &event); err != nil {
					log.Printf("Failed to parse perf event: %s", err)
					break
				}

				// print parsed event
				log.Printf("Event - CPU: %d, RMID: %d, Time Delta: %d ns, Cycles Delta: %d, Instructions Delta: %d, LLC Misses Delta: %d, Timestamp: %d",
					cpuID, event.Rmid, event.TimeDeltaNs, event.CyclesDelta, event.InstructionsDelta, event.LlcMissesDelta, event.Timestamp)
				totalEvents++

				reader.Pop()
			}

			if err := reader.Finish(); err != nil {
				log.Printf("Error finishing reader: %s", err)
			}

			// Output counts every second
			var count uint64
			var key uint32 = 0
			if err := objs.EventCount.Lookup(&key, &count); err != nil {
				log.Fatal(err)
			}
			log.Printf("Event count: userspace %d, eBPF %d\n", totalEvents, count)
		}
	}
}
