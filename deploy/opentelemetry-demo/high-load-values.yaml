# OpenTelemetry Demo - High Load Configuration
# Targets c5.9xlarge (36 vCPUs) with 70% utilization (~25 cores)

global:
  logLevel: debug
  resources:
    limits:
      cpu: "36"
      memory: "72Gi"

# Enhanced Load Generation Configuration
loadGenerator:
  replicas: 4  # Distribute load generation across multiple pods
  resources:
    requests:
      cpu: "4"
      memory: "4Gi"
    limits:
      cpu: "8"
      memory: "8Gi"
  config:
    frontendUsersPerSecond: 1000  # Drastically increased from default 10
    checkoutUsersPerSecond: 400    # Increased from default 1
    maxVirtualUsers: 10000        # Increased concurrent user capacity
    rampUpTimeSeconds: 900        # 15 minute ramp up period
    testDurationSeconds: 3600     # 1 hour test duration
    thinkTimeMilliseconds: 100    # Reduced think time between actions
    addToCartPercentage: 30       # More cart operations
    checkoutPercentage: 20       # More checkouts

# Frontend Service Configuration (typically first bottleneck)
frontend:
  replicas: 6
  resources:
    requests:
      cpu: "2"
      memory: "2Gi"
    limits:
      cpu: "4"
      memory: "4Gi"
  autoscaling:
    enabled: true
    minReplicas: 6
    maxReplicas: 12
    targetCPUUtilizationPercentage: 80

# Backend Services Configuration (scale based on expected bottlenecks)
productcatalogservice:
  replicas: 4
  resources:
    requests:
      cpu: "3"
      memory: "4Gi"
    limits:
      cpu: "6"
      memory: "8Gi"

cartservice:
  replicas: 4
  resources:
    requests:
      cpu: "2"
      memory: "4Gi"
    limits:
      cpu: "4"
      memory: "8Gi"

checkoutservice:
  replicas: 4
  resources:
    requests:
      cpu: "2"
      memory: "2Gi"
    limits:
      cpu: "4"
      memory: "4Gi"

recommendationservice:
  replicas: 4
  resources:
    requests:
      cpu: "2"
      memory: "2Gi"
    limits:
      cpu: "4"
      memory: "4Gi"

# Database Services Configuration
redis:
  resources:
    requests:
      cpu: "4"
      memory: "16Gi"
    limits:
      cpu: "8"
      memory: "32Gi"
  master:
    replicas: 3

postgresql:
  primary:
    resources:
      requests:
        cpu: "4"
        memory: "16Gi"
      limits:
        cpu: "8"
        memory: "32Gi"

# Observability Components Configuration (scale up to handle increased load)
opentelemetry-collector:
  mode: deployment
  replicas: 3
  resources:
    requests:
      cpu: "2"
      memory: "4Gi"
    limits:
      cpu: "4"
      memory: "8Gi"

prometheus:
  server:
    resources:
      requests:
        cpu: "4"
        memory: "16Gi"
      limits:
        cpu: "8"
        memory: "32Gi"

grafana:
  resources:
    requests:
      cpu: "2"
      memory: "4Gi"
    limits:
      cpu: "4"
      memory: "8Gi"

# Feature Flags for High Load Scenario
featureFlags:
  enableAdvancedLoadPatterns: true
  enableStressTestingMode: true
  cacheEnabled: true
  highAvailabilityMode: true